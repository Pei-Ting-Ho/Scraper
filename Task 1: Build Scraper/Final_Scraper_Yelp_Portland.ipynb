{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an API key to avoid getting blocked\n",
    "from scraper_api import ScraperAPIClient\n",
    "client = ScraperAPIClient('6d9b6cc5f371488e4e50d19f55b17db5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over multiple search results pages: 30 results per page * 10 pages\n",
    "object_name = []\n",
    "object_href = []\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        url = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=Portland%2C+OR&ns=1'\n",
    "    else:\n",
    "        url = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=Portland%2C%20OR&start=' + str(i * 30)\n",
    "    main_page = client.get(url).text\n",
    "    # Soup\n",
    "    soup = BeautifulSoup(main_page, 'lxml')\n",
    "    # Link\n",
    "    subpages = soup.select('.text-size--inherit__373c0__2fB3p .link-color--inherit__373c0__3dzpk')\n",
    "    # Exclude the sponsored results\n",
    "    for j in subpages[2:32]:\n",
    "        object_name.append(j.string)\n",
    "        object_href.append(j.get('href'))\n",
    "\n",
    "# DataFrame: Business name; Business link\n",
    "object_href = ['https://www.yelp.com' + url for url in object_href]\n",
    "object_data = list(zip(object_name, object_href))\n",
    "object_df = pd.DataFrame(data = object_data, columns = ['name', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect duplicated values: 12\n",
    "print(sum(object_df.duplicated(subset = ['name'], keep = 'first')))\n",
    "\n",
    "# Drop duplicated values\n",
    "object_df.drop_duplicates(subset = ['name'], keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to the csv file\n",
    "with open('Business.csv', 'a', newline = '') as f:\n",
    "    object_df.to_csv(f, index = False, header = True, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate the tree\n",
    "\n",
    "# The find method: \n",
    "# # Signature: find(name, attrs, recursive, string, **kwargs)\n",
    "# # If find() canâ€™t find anything, it returns None.\n",
    "\n",
    "# The find_all method:\n",
    "# # Signature: find_all(name, attrs, recursive, string, limit, **kwargs)\n",
    "# # Search by a class attribute: class_=\n",
    "# # Search by a dictionary: {\"attribute\": \"value\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the reviews information\n",
    "# The 'if-else' is to make sure the extracted info is not empty\n",
    "def crawl_review_page(client, review_url):\n",
    "    reviews_info = []\n",
    "\n",
    "    html = client.get(review_url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    reviwers_block_list = soup.find_all('li', {'class': 'lemon--li__373c0__1r9wz margin-b3__373c0__q1DuY padding-b3__373c0__342DA border--bottom__373c0__3qNtD border-color--default__373c0__3-ifU'})\n",
    "    for reviewer_block in reviwers_block_list:\n",
    "        # Reviewers: Name\n",
    "        reviewer_name = reviewer_block.find('span', {'class': 'lemon--span__373c0__3997G text__373c0__2Kxyz fs-block text-color--blue-dark__373c0__1jX7S text-align--left__373c0__2XGa- text-weight--bold__373c0__1elNz'}).text\n",
    "  \n",
    "        # Reviewers: Location\n",
    "        reviewers_location_info = reviewer_block.find('span', {'class': 'lemon--span__373c0__3997G text__373c0__2Kxyz text-color--normal__373c0__3xep9 text-align--left__373c0__2XGa- text-weight--bold__373c0__1elNz text-size--small__373c0__3NVWO'})\n",
    "        if reviewers_location_info == None:\n",
    "            reviewer_location = 'NA'\n",
    "        else:\n",
    "            reviewer_location = reviewers_location_info.text\n",
    "\n",
    "        # Reviewers: Number of friends\n",
    "        reviewer_friends_icon = reviewer_block.find('span', {'class': 'icon--18-friends'})\n",
    "        if reviewer_friends_icon == None:\n",
    "            reviewer_friends = 'NA'\n",
    "        else:\n",
    "            reviewer_friends = reviewer_friends_icon.next_sibling.text.split()[0]\n",
    "\n",
    "        # Reviewers: Number of reviews\n",
    "        reviewers_reviews_icon = reviewer_block.find('span', {'class': 'icon--18-review'})\n",
    "        if reviewers_reviews_icon == None:\n",
    "            reviewer_reviews = 'NA'\n",
    "        else:\n",
    "            reviewer_reviews = reviewers_reviews_icon.next_sibling.text.split()[0]\n",
    "\n",
    "        # Reviewers: Number of photos\n",
    "        reviewers_photos_icon = reviewer_block.find('span', {'class': 'icon--18-camera'})\n",
    "        if reviewers_photos_icon == None:\n",
    "            reviewer_photos = 'NA'\n",
    "        else:\n",
    "            reviewer_photos = reviewers_photos_icon.next_sibling.text.split()[0]\n",
    "\n",
    "        # Reviewers: Ratings\n",
    "        reviewers_ratings_img = reviewer_block.find('img', {'class': 'lemon--img__373c0__3GQUb offscreen__373c0__1KofL'})\n",
    "        reviewer_ratings = reviewers_ratings_img.parent.attrs['aria-label']\n",
    "        reviewer_ratings = float(reviewer_ratings.split(' ')[0])\n",
    "    \n",
    "        # Reviewers: Text\n",
    "        reviewers_text_info = reviewer_block.find('span', {'class': 'lemon--span__373c0__3997G raw__373c0__3rKqk'})\n",
    "        if reviewers_text_info == None:\n",
    "            reviewer_text = 'NA'\n",
    "        else:\n",
    "            reviewer_text = reviewers_text_info.text\n",
    "        \n",
    "        # Reviewers: Rating dates\n",
    "        reviewers_date_info = reviewer_block.find_all('span', {'class': 'lemon--span__373c0__3997G text__373c0__2Kxyz text-color--mid__373c0__jCeOG text-align--left__373c0__2XGa-'}, limit = 1)\n",
    "        for j in reviewers_date_info:\n",
    "            if j == None:\n",
    "                reviewer_date = 'NA'\n",
    "            else:\n",
    "                reviewer_date = j.text\n",
    "        \n",
    "        # Put together \n",
    "        reviews_info += [(reviewer_name, reviewer_location, reviewer_friends, reviewer_reviews, reviewer_photos, reviewer_ratings, reviewer_text, reviewer_date)]\n",
    "\n",
    "    return reviews_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the output\n",
    "crawl_review_page(client, 'https://www.yelp.com/biz/screen-door-portland?osq=Restaurants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the scraper output\n",
    "for i in range(3):\n",
    "    business_link = object_df.iloc[i]['url']\n",
    "    business_name = object_df.iloc[i]['name']\n",
    "    obs = client.get(business_link).text\n",
    "    soup = BeautifulSoup(obs, 'lxml')\n",
    "    \n",
    "    # One-to-one mapping: Get each business page information\n",
    "    # # Name\n",
    "    name = []\n",
    "    name += [business_name]\n",
    "    \n",
    "    # # Total ratings\n",
    "    ratings_img = soup.find('img', {'class': 'lemon--img__373c0__3GQUb offscreen__373c0__1KofL'})\n",
    "    overall_ratings = []\n",
    "    if ratings_img:\n",
    "        ratings_info = ratings_img.parent\n",
    "        overall_ratings.append(ratings_info.attrs['aria-label'])\n",
    "    else:\n",
    "        overall_ratings.append('NA')\n",
    "    overall_ratings = [re.sub(' star rating', '',  r) for r in overall_ratings]\n",
    "    overall_ratings = [float(r) for r in overall_ratings]\n",
    "\n",
    "    # # Style\n",
    "    styles_info = soup.select('.margin-r1__373c0__zyKmV .link-size--inherit__373c0__1VFlE')\n",
    "    styles = []\n",
    "    if styles_info:\n",
    "        for j in styles_info:\n",
    "            styles.append(j.get_text())\n",
    "    else:\n",
    "        styles.append('NA')\n",
    "\n",
    "    # # Price range\n",
    "    price_info = soup.select('.text-bullet--after__373c0__3fS1Z.text-size--large__373c0__3t60B')\n",
    "    price = []\n",
    "    for j in price_info:\n",
    "        price.append(j.get_text().replace(' ', ''))\n",
    "\n",
    "    # # Number of reviews\n",
    "    num_reviews_info = soup.select('.text-color--mid__373c0__jCeOG.text-size--large__373c0__3t60B')\n",
    "    num_reviews = []\n",
    "    for j in num_reviews_info:\n",
    "        num_reviews.append(int(j.get_text().split(' ')[0]))\n",
    "\n",
    "    # # Number of photos\n",
    "    num_photos_info = soup.find_all('a', {'class': 'lemon--a__373c0__IEZFH button__373c0__3lYgT secondary-white__373c0__2OPxz'}, limit = 1)\n",
    "    num_photos = []\n",
    "    if num_photos_info:\n",
    "        for j in num_photos_info:\n",
    "            num_photos.append(j.get_text().split(' ')[2])\n",
    "    else:\n",
    "        num_photos.append('NA')\n",
    "\n",
    "    # # Highlights\n",
    "    high_info = soup.select('.display--inline-block__373c0__1ZKqC.margin-r1__373c0__zyKmV')\n",
    "    high = []\n",
    "    if high_info:\n",
    "        for j in high_info:\n",
    "            high.append(j.get_text().split(' ')[0])\n",
    "    else:\n",
    "        high.append('NA')\n",
    "    \n",
    "    # # DataFrame\n",
    "    rating_data = list(zip(name, \n",
    "                           overall_ratings, \n",
    "                           styles, \n",
    "                           price,\n",
    "                           num_reviews,\n",
    "                           num_photos,\n",
    "                           high))\n",
    "    rating_df = pd.DataFrame(data = rating_data, columns = ['name',\n",
    "                                                            'rating',\n",
    "                                                            'styles',\n",
    "                                                            'price_range',\n",
    "                                                            'num_reviews',\n",
    "                                                            'num_photos',\n",
    "                                                            'highlights'])\n",
    "    with open('Rating.csv', 'a', newline = '') as f:\n",
    "        rating_df.to_csv(f, index = False, header = False, encoding = 'utf8')\n",
    "    \n",
    "    # One-to-many mapping: Get each review page information\n",
    "    # # Use the defined function to retrieve the info\n",
    "    reviewers_info = []\n",
    "    for k in range(0, 3):\n",
    "        if k == 0:\n",
    "            review_link = business_link\n",
    "        else:\n",
    "            review_link = business_link + '&start=' + str(k * 20)\n",
    "        print(review_link)\n",
    "        page_reviewers_info = crawl_review_page(client, review_link)\n",
    "        reviewers_info += page_reviewers_info\n",
    "        \n",
    "    # # DataFrame\n",
    "    review_data = [(business_name, business_link, *(reviewers_info[i][:])) for i in range(len(reviewers_info))]  \n",
    "    review_df = pd.DataFrame(data = review_data, columns = ['business', \n",
    "                                                            'hyperreference',\n",
    "                                                            'reviewers',\n",
    "                                                            'reviewers_location',\n",
    "                                                            'reviewers_num_friends',\n",
    "                                                            'reviewers_num_photos',\n",
    "                                                            'reviewers_num_reviews',\n",
    "                                                            'reviewers_rating',\n",
    "                                                            'reviewers_text',\n",
    "                                                            'reviewers_rating_date'])\n",
    "    with open('Review.csv', 'a', newline = '') as f:\n",
    "        review_df.to_csv(f, index = False, header = False, encoding = 'utf8')\n",
    "            \n",
    "    print(f'Page {i}: O') \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the whole scraper\n",
    "for i in range(len(object_df)):\n",
    "    business_link = object_df.iloc[i]['url']\n",
    "    business_name = object_df.iloc[i]['name']\n",
    "    obs = client.get(business_link).text\n",
    "    soup = BeautifulSoup(obs, 'lxml')\n",
    "    \n",
    "    # One-to-one mapping: Get each business page information\n",
    "    # # Name\n",
    "    name = []\n",
    "    name += [business_name]\n",
    "    \n",
    "    # # Total ratings\n",
    "    ratings_img = soup.find('img', {'class': 'lemon--img__373c0__3GQUb offscreen__373c0__1KofL'})\n",
    "    overall_ratings = []\n",
    "    if ratings_img:\n",
    "        ratings_info = ratings_img.parent\n",
    "        overall_ratings.append(ratings_info.attrs['aria-label'])\n",
    "    else:\n",
    "        overall_ratings.append('NA')\n",
    "    overall_ratings = [re.sub(' star rating', '',  r) for r in overall_ratings]\n",
    "    overall_ratings = [float(r) for r in overall_ratings]\n",
    "\n",
    "    # # Style\n",
    "    styles_info = soup.select('.margin-r1__373c0__zyKmV .link-size--inherit__373c0__1VFlE')\n",
    "    styles = []\n",
    "    if styles_info:\n",
    "        for j in styles_info:\n",
    "            styles.append(j.get_text())\n",
    "    else:\n",
    "        styles.append('NA')\n",
    "\n",
    "    # # Price range\n",
    "    price_info = soup.select('.text-bullet--after__373c0__3fS1Z.text-size--large__373c0__3t60B')\n",
    "    price = []\n",
    "    for j in price_info:\n",
    "        price.append(j.get_text().replace(' ', ''))\n",
    "\n",
    "    # # Number of reviews\n",
    "    num_reviews_info = soup.select('.text-color--mid__373c0__jCeOG.text-size--large__373c0__3t60B')\n",
    "    num_reviews = []\n",
    "    for j in num_reviews_info:\n",
    "        num_reviews.append(int(j.get_text().split(' ')[0]))\n",
    "\n",
    "    # # Number of photos\n",
    "    num_photos_info = soup.find_all('a', {'class': 'lemon--a__373c0__IEZFH button__373c0__3lYgT secondary-white__373c0__2OPxz'}, limit = 1)\n",
    "    num_photos = []\n",
    "    if num_photos_info:\n",
    "        for j in num_photos_info:\n",
    "            num_photos.append(j.get_text().split(' ')[2])\n",
    "    else:\n",
    "        num_photos.append('NA')\n",
    "\n",
    "    # # Highlights\n",
    "    high_info = soup.select('.display--inline-block__373c0__1ZKqC.margin-r1__373c0__zyKmV')\n",
    "    high = []\n",
    "    if high_info:\n",
    "        for j in high_info:\n",
    "            high.append(j.get_text().split(' ')[0])\n",
    "    else:\n",
    "        high.append('NA')\n",
    "    \n",
    "    # # DataFrame\n",
    "    rating_data = list(zip(name, \n",
    "                           overall_ratings, \n",
    "                           styles, \n",
    "                           price,\n",
    "                           num_reviews,\n",
    "                           num_photos,\n",
    "                           high))\n",
    "    rating_df = pd.DataFrame(data = rating_data, columns = ['name',\n",
    "                                                            'rating',\n",
    "                                                            'styles',\n",
    "                                                            'price_range',\n",
    "                                                            'num_reviews',\n",
    "                                                            'num_photos',\n",
    "                                                            'highlights'])\n",
    "    with open('Rating.csv', 'a', newline = '') as f:\n",
    "        rating_df.to_csv(f, index = False, header = False, encoding = 'utf8')\n",
    "    \n",
    "    # One-to-many mapping: Get each review page information\n",
    "    # # Use the defined function to retrieve the info\n",
    "    reviewers_info = []\n",
    "    for k in range(0, 3):\n",
    "        if k == 0:\n",
    "            review_link = business_link\n",
    "        else:\n",
    "            review_link = business_link + '&start=' + str(k * 20)\n",
    "        print(review_link)\n",
    "        page_reviewers_info = crawl_review_page(client, review_link)\n",
    "        reviewers_info += page_reviewers_info\n",
    "        \n",
    "    # # DataFrame\n",
    "    review_data = [(business_name, business_link, *(reviewers_info[i][:])) for i in range(len(reviewers_info))]  \n",
    "    review_df = pd.DataFrame(data = review_data, columns = ['business', \n",
    "                                                            'hyperreference',\n",
    "                                                            'reviewers',\n",
    "                                                            'reviewers_location',\n",
    "                                                            'reviewers_num_friends',\n",
    "                                                            'reviewers_num_photos',\n",
    "                                                            'reviewers_num_reviews',\n",
    "                                                            'reviewers_rating',\n",
    "                                                            'reviewers_text', \n",
    "                                                            'reviewers_rating_date'])\n",
    "    with open('Review.csv', 'a', newline = '') as f:\n",
    "        review_df.to_csv(f, index = False, header = False, encoding = 'utf8')\n",
    "            \n",
    "    print(f'Page {i}: O') \n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
